"""
surge_factor.py - Surgeå› å­è®¡ç®—å™¨ï¼ˆä¿®å¤ç‰ˆï¼‰

ä¿®å¤å†…å®¹ï¼š
1. M10è¾“å‡ºï¼šæ— è®ºç”¨1m/5m/10mæŒ–æ˜ï¼Œæœ€ç»ˆéƒ½èšåˆåˆ°M10çš„24ä¸ªæ—¶é—´ç‚¹
2. EODè¾“å‡ºï¼šbar_timeç»Ÿä¸€ä¸º15:00:00.000
"""

import polars as pl
import numpy as np
from datetime import time, datetime, timedelta
from typing import List, Literal, Optional, Union, Dict

from dux.cal import bizdays, bizday

from data_loader import DataLoader
from bar_builder import BarBuilder
from config import (
    get_timestamps, 
    get_bar_count_per_day,
    get_trading_time_slice,
    get_bars_per_trading_time,
    M10_TIMESTAMPS,
    DAILY_TIMESTAMPS,
)


# ============================================================
# M10æ—¶é—´æ˜ å°„å·¥å…·
# ============================================================

def get_m10_bar_time(bar_time: time) -> time:
    """
    å°†ä»»æ„bar_timeæ˜ å°„åˆ°å¯¹åº”çš„M10 bar_time
    
    è§„åˆ™ï¼šä½¿ç”¨å·¦å¼€å³é—­ (start, end]
    - (09:30, 09:40] â†’ 09:40
    - (09:40, 09:50] â†’ 09:50
    - ...
    
    Args:
        bar_time: åŸå§‹baræ—¶é—´ï¼ˆå¯èƒ½æ˜¯1m/5m/10mï¼‰
    
    Returns:
        å¯¹åº”çš„M10 baræ—¶é—´
    """
    # M10çš„æ—¶é—´ç‚¹åˆ—è¡¨
    m10_times = [time.fromisoformat(t.replace(".000", "")) for t in M10_TIMESTAMPS]
    
    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯åˆä¼‘å‰çš„æ—¶é—´(11:30ä¹‹åï¼Œ13:00ä¹‹å‰)ï¼Œå½’åˆ°11:30
    if time(11, 30) < bar_time < time(13, 0):
        return time(11, 30)
    
    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯æ”¶ç›˜å(15:00ä¹‹å)ï¼Œå½’åˆ°15:00
    if bar_time > time(15, 0):
        return time(15, 0)
    
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ª >= bar_time çš„M10æ—¶é—´ç‚¹
    for m10_time in m10_times:
        if m10_time >= bar_time:
            return m10_time
    
    # é»˜è®¤è¿”å›æœ€åä¸€ä¸ªï¼ˆ15:00ï¼‰
    return m10_times[-1]


def build_m10_bar_time_mapping() -> Dict[time, time]:
    """
    æ„å»ºä»1m/5m bar_timeåˆ°M10 bar_timeçš„æ˜ å°„è¡¨
    
    Returns:
        Dict[åŸå§‹time, M10 time]
    """
    from config import M1_TIMESTAMPS, M5_TIMESTAMPS
    
    mapping = {}
    
    # å¤„ç†æ‰€æœ‰1mæ—¶é—´ç‚¹
    for t_str in M1_TIMESTAMPS:
        t = time.fromisoformat(t_str.replace(".000", ""))
        mapping[t] = get_m10_bar_time(t)
    
    # å¤„ç†æ‰€æœ‰5mæ—¶é—´ç‚¹
    for t_str in M5_TIMESTAMPS:
        t = time.fromisoformat(t_str.replace(".000", ""))
        mapping[t] = get_m10_bar_time(t)
    
    # å¤„ç†æ‰€æœ‰10mæ—¶é—´ç‚¹ï¼ˆæ˜ å°„åˆ°è‡ªå·±ï¼‰
    for t_str in M10_TIMESTAMPS:
        t = time.fromisoformat(t_str.replace(".000", ""))
        mapping[t] = t
    
    return mapping


class SurgeFactor:
    """
    Surgeå› å­è®¡ç®—å™¨ï¼ˆä¿®å¤ç‰ˆï¼‰
    
    ä¿®å¤å†…å®¹ï¼š
    1. M10è¾“å‡ºï¼šæ— è®ºç”¨1m/5m/10mæŒ–æ˜ï¼Œæœ€ç»ˆéƒ½èšåˆåˆ°M10çš„24ä¸ªæ—¶é—´ç‚¹
    2. EODè¾“å‡ºï¼šbar_timeç»Ÿä¸€ä¸º15:00:00.000
    """
    
    def __init__(
        self,
        # ===== åŸºç¡€å‚æ•° =====
        bar_freq: str = "1m",
        output_freq: str = "EOD",
        
        # ===== Surgeè¯†åˆ«å‚æ•° =====
        threshold: float = 1.0,
        
        # ===== EODä¸“ç”¨å‚æ•° =====
        trading_time: str = "all_day",
        factor_type: str = "surge_ret",
        surge_window: int = 5,
        
        # ===== M10ä¸“ç”¨å‚æ•° =====
        m10_method: str = "same_time",
        lookback_days: int = 20,
        lookback_bars: int = 48,
        
        # ===== èšåˆç»Ÿè®¡é‡ =====
        intraday_stat: str = "mean",
        
        # ===== å…¶ä»–å‚æ•° =====
        price_type: str = None,
        data_path: str = None,
    ):
        # è½¬æ¢ "1m" -> "M1", "5m" -> "M5", "10m" -> "M10"
        freq_map = {
            "1m": "M1", "1min": "M1", "m1": "M1",
            "5m": "M5", "5min": "M5", "m5": "M5",
            "10m": "M10", "10min": "M10", "m10": "M10",
        }
        self.bar_freq = freq_map.get(bar_freq.lower(), bar_freq.upper())
        self.output_freq = output_freq.upper()
        self.threshold = threshold
        
        # EODå‚æ•°
        self.trading_time = trading_time
        self.factor_type = factor_type
        self.surge_window = surge_window
        
        # M10å‚æ•°
        self.m10_method = m10_method
        self.lookback_days = lookback_days
        self.lookback_bars = lookback_bars
        
        # èšåˆç»Ÿè®¡é‡
        self.intraday_stat = intraday_stat
        
        # å…¶ä»–å‚æ•°
        self.price_type = price_type
        
        # åˆå§‹åŒ–loaderå’Œbuilder
        self.loader = DataLoader(data_path=data_path) if data_path else DataLoader()
        self.bar_builder = BarBuilder(freq=bar_freq)
        
        # å‚æ•°éªŒè¯
        self._validate_params()
        
        # å­˜å‚¨æ•°æ®çš„å±æ€§
        self.bar_data = None
        
        # æ„å»ºM10æ˜ å°„è¡¨ï¼ˆç”¨äºèšåˆï¼‰
        self._m10_mapping = build_m10_bar_time_mapping()
    
    def _validate_params(self):
        """å‚æ•°éªŒè¯"""
        if self.output_freq not in ["EOD", "M10"]:
            raise ValueError(f"output_freqå¿…é¡»æ˜¯'EOD'æˆ–'M10'ï¼Œå½“å‰: {self.output_freq}")
        
        if self.output_freq == "EOD":
            if self.factor_type not in ["surge_ret", "surge_vol"]:
                raise ValueError(f"factor_typeå¿…é¡»æ˜¯'surge_ret'æˆ–'surge_vol'ï¼Œå½“å‰: {self.factor_type}")
        
        if self.output_freq == "M10":
            if self.m10_method not in ["same_time", "rolling"]:
                raise ValueError(f"m10_methodå¿…é¡»æ˜¯'same_time'æˆ–'rolling'ï¼Œå½“å‰: {self.m10_method}")
            if self.factor_type != "surge_ret":
                print(f"âš ï¸  M10æ¨¡å¼åªæ”¯æŒsurge_retï¼Œå·²è‡ªåŠ¨è®¾ç½®")
                self.factor_type = "surge_ret"
        
        print(f"âœ“ å‚æ•°éªŒè¯é€šè¿‡")
        print(f"  - è¾“å‡ºæ¨¡å¼: {self.output_freq}")
        print(f"  - Baré¢‘ç‡: {self.bar_freq}")
        print(f"  - å› å­ç±»å‹: {self.factor_type}")
        print(f"  - èšåˆç»Ÿè®¡é‡: {self.intraday_stat}")
        if self.output_freq == "EOD":
            print(f"  - äº¤æ˜“æ—¶æ®µ: {self.trading_time}")
        else:
            print(f"  - M10æ–¹æ³•: {self.m10_method}")
            if self.m10_method == "same_time":
                print(f"  - å›çœ‹å¤©æ•°: {self.lookback_days}")
            else:
                print(f"  - å›çœ‹Baræ•°: {self.lookback_bars}")

    # ============================================================
    # æ•°æ®åŠ è½½éƒ¨åˆ†
    # ============================================================
    
    def load_and_build_bars(
        self, 
        bizdays_str: str = None,
        date_list: List[str] = None,
        add_intraday_ret: bool = True
    ) -> pl.DataFrame:
        """åŠ è½½tradeæ•°æ®å¹¶åˆæˆbar"""
        if date_list is not None:
            dates = date_list
        elif bizdays_str is not None:
            dates = bizdays(bizdays_str)
        else:
            raise ValueError("å¿…é¡»æä¾› bizdays_str æˆ– date_list")
        
        print(f"ğŸ“Š åŠ è½½æ•°æ®: {dates[0]} ~ {dates[-1]}ï¼Œå…± {len(dates)} å¤©ï¼Œé¢‘ç‡: {self.bar_freq}")
        
        trade_lf = self.loader.load_trade(
            date_list=dates,
            columns=["inst_id", "xts", "px", "qty", "amt", "flag"]
        )
        
        bar_df = self.bar_builder.group_by_bar_trade(
            lf=trade_lf,
            time_col="xts",
            price_col="px",
            qty_col="qty",
            amt_col="amt",
            flag_col="flag",
            filter_valid=True
        )
        
        print(f"âœ“ Baræ•°æ®ç”Ÿæˆå®Œæˆ: {len(bar_df)} æ¡è®°å½•")
        print(f"  - è‚¡ç¥¨æ•°: {bar_df['symbol'].n_unique()}")
        print(f"  - æ—¥æœŸèŒƒå›´: {bar_df['date'].min()} ~ {bar_df['date'].max()}")
        
        if add_intraday_ret:
            bar_df = self._add_bar_returns(bar_df)
        
        self.bar_data = bar_df
        return bar_df
    
    def _add_bar_returns(self, bar_df: pl.DataFrame) -> pl.DataFrame:
        """æ·»åŠ barå†…æ”¶ç›Šç‡"""
        return bar_df.with_columns(
            pl.when(pl.col("open") <= 0)
            .then(None)
            .otherwise((pl.col("close") - pl.col("open")) / pl.col("open"))
            .alias("bar_ret")
        )

    # ============================================================
    # ã€æ ¸å¿ƒä¿®å¤ã€‘æ·»åŠ M10 bar_timeæ˜ å°„
    # ============================================================
    
    def _add_m10_bar_time(self, df: pl.DataFrame) -> pl.DataFrame:
        """
        æ·»åŠ m10_bar_timeåˆ—ï¼Œå°†ä»»æ„é¢‘ç‡çš„bar_timeæ˜ å°„åˆ°M10æ—¶é—´ç‚¹
        
        ç”¨äºM10è¾“å‡ºæ—¶çš„èšåˆ
        """
        # æå–bar_timeçš„æ—¶é—´éƒ¨åˆ†
        bar_times = df["bar_time"].dt.time().to_list()
        
        # æ˜ å°„åˆ°M10æ—¶é—´
        m10_times = [self._m10_mapping.get(t, t) for t in bar_times]
        
        # é‡å»ºå®Œæ•´çš„datetimeï¼ˆä¿ç•™æ—¥æœŸéƒ¨åˆ†ï¼‰
        dates = df["bar_time"].dt.date().to_list()
        m10_datetimes = [
            datetime.combine(d, t) for d, t in zip(dates, m10_times)
        ]
        
        return df.with_columns(
            pl.Series("m10_bar_time", m10_datetimes).cast(pl.Datetime)
        )

    # ============================================================
    # Surgeè¯†åˆ«éƒ¨åˆ† - EODæ¨¡å¼
    # ============================================================
    
    def _identify_surge_eod(self, bar_df: pl.DataFrame) -> pl.DataFrame:
        """EODæ¨¡å¼çš„surgeè¯†åˆ«"""
        print(f"ğŸ” EOD Surgeè¯†åˆ«: {self.trading_time}, threshold={self.threshold}")
        
        valid_times = get_trading_time_slice(self.bar_freq, self.trading_time)
        
        print(f"  - Baré¢‘ç‡: {self.bar_freq}")
        print(f"  - æœ‰æ•ˆæ—¶é—´æ®µæ•°: {len(valid_times)}")
        
        df = bar_df.filter(
            pl.col("bar_time").dt.time().is_in(valid_times)
        )
        
        print(f"  - ç­›é€‰åbaræ•°: {len(df)}")
        
        df = df.with_columns([
            pl.col("vol").mean().over(["symbol", "date"]).alias("vol_mean"),
            pl.col("vol").std().over(["symbol", "date"]).alias("vol_std"),
        ])
        
        df = df.with_columns(
            pl.when(pl.col("vol_std").is_null() | (pl.col("vol_std") == 0))
            .then(False)
            .otherwise(
                pl.col("vol") > (pl.col("vol_mean") + self.threshold * pl.col("vol_std"))
            )
            .alias("is_surge")
        )
        
        surge_ratio = df["is_surge"].sum() / len(df)
        print(f"  - Surgeå æ¯”: {surge_ratio:.2%}")
        
        return df

    # ============================================================
    # Surgeè¯†åˆ«éƒ¨åˆ† - M10 same_timeæ¨¡å¼
    # ============================================================
    
    def _identify_surge_m10_same_time(self, bar_df: pl.DataFrame) -> pl.DataFrame:
        """
        M10æ¨¡å¼ - same_timeæ–¹æ³•
        
        ã€é‡è¦ã€‘Surgeè¯†åˆ«ä½¿ç”¨åŸå§‹bar_timeï¼ˆ1m/5m/10mï¼‰ï¼Œä¸æ˜¯M10æ—¶é—´ç‚¹
        M10èšåˆåœ¨åç»­çš„_aggregate_surge_retä¸­è¿›è¡Œ
        """
        print(f"ğŸ” M10 Surgeè¯†åˆ« (same_time): H={self.lookback_days}å¤©, threshold={self.threshold}")
        
        # ä½¿ç”¨åŸå§‹bar_timeçš„æ—¶é—´éƒ¨åˆ†è¿›è¡ŒåŒæ—¶åˆ»æ¯”è¾ƒ
        bar_df = bar_df.with_columns(
            pl.col("bar_time").dt.time().alias("bar_time_only")
        )
        
        dates = sorted(bar_df["date"].unique().to_list())
        
        result_list = []
        
        for target_date in dates:
            date_idx = dates.index(target_date)
            lookback_dates = dates[max(0, date_idx - self.lookback_days):date_idx]
            
            if len(lookback_dates) < self.lookback_days:
                print(f"  âš ï¸  {target_date}: å†å²æ•°æ®ä¸è¶³({len(lookback_dates)}å¤© < {self.lookback_days}å¤©)ï¼Œè·³è¿‡")
                continue
            
            baseline_df = bar_df.filter(pl.col("date").is_in(lookback_dates))
            
            # ä½¿ç”¨åŸå§‹bar_time_onlyè¿›è¡ŒåŒæ—¶åˆ»æ¯”è¾ƒï¼ˆå¦‚09:31æ¯”09:31ï¼Œ09:32æ¯”09:32ï¼‰
            baseline_stats = (
                baseline_df
                .group_by(["symbol", "bar_time_only"])
                .agg([
                    pl.col("vol").mean().alias("vol_mean_baseline"),
                    pl.col("vol").std().alias("vol_std_baseline"),
                ])
            )
            
            target_df = bar_df.filter(pl.col("date") == target_date)
            
            target_df = target_df.join(
                baseline_stats,
                on=["symbol", "bar_time_only"],
                how="left"
            )
            
            target_df = target_df.with_columns(
                pl.when(
                    pl.col("vol_std_baseline").is_null() | 
                    (pl.col("vol_std_baseline") == 0)
                )
                .then(False)
                .otherwise(
                    pl.col("vol") > (pl.col("vol_mean_baseline") + self.threshold * pl.col("vol_std_baseline"))
                )
                .alias("is_surge")
            )
            
            result_list.append(target_df)
        
        if not result_list:
            raise ValueError(f"æ‰€æœ‰æ—¥æœŸçš„å†å²æ•°æ®éƒ½ä¸è¶³{self.lookback_days}å¤©ï¼Œæ— æ³•è®¡ç®—surge")
        
        result_df = pl.concat(result_list)
        result_df = result_df.drop("bar_time_only")
        
        surge_ratio = result_df["is_surge"].sum() / len(result_df)
        print(f"  - æœ‰æ•ˆæ—¥æœŸæ•°: {len(result_list)}/{len(dates)}")
        print(f"  - Surgeå æ¯”: {surge_ratio:.2%}")
        
        return result_df

    # ============================================================
    # Surgeè¯†åˆ«éƒ¨åˆ† - M10 rollingæ¨¡å¼
    # ============================================================
    
    def _identify_surge_m10_rolling(self, bar_df: pl.DataFrame) -> pl.DataFrame:
        """
        M10æ¨¡å¼ - rollingæ–¹æ³•
        
        ã€é‡è¦ã€‘Surgeè¯†åˆ«ä½¿ç”¨åŸå§‹bar_timeï¼ˆ1m/5m/10mï¼‰çš„é¡ºåº
        M10èšåˆåœ¨åç»­çš„_aggregate_surge_retä¸­è¿›è¡Œ
        """
        print(f"ğŸ” M10 Surgeè¯†åˆ« (rolling): k={self.lookback_bars}æ ¹, threshold={self.threshold}")
        
        # ä¸åœ¨è¿™é‡Œæ·»åŠ m10_bar_timeï¼Œä¿æŒåŸå§‹baré¡ºåºè¿›è¡Œrolling
        df = bar_df.sort(["symbol", "date", "bar_time"])
        
        df = df.with_columns([
            pl.col("vol")
              .rolling_mean(window_size=self.lookback_bars, min_periods=self.lookback_bars)
              .shift(1)
              .over("symbol")
              .alias("vol_mean_baseline"),
            
            pl.col("vol")
              .rolling_std(window_size=self.lookback_bars, min_periods=self.lookback_bars)
              .shift(1)
              .over("symbol")
              .alias("vol_std_baseline"),
        ])
        
        df = df.with_columns(
            pl.when(
                pl.col("vol_std_baseline").is_null() | 
                (pl.col("vol_std_baseline") == 0)
            )
            .then(False)
            .otherwise(
                pl.col("vol") > (pl.col("vol_mean_baseline") + self.threshold * pl.col("vol_std_baseline"))
            )
            .alias("is_surge")
        )
        
        valid_count = df["is_surge"].is_not_null().sum()
        surge_count = df["is_surge"].sum()
        surge_ratio = surge_count / valid_count if valid_count > 0 else 0
        
        print(f"  - æœ‰æ•ˆbaræ•°: {valid_count}/{len(df)}")
        print(f"  - Surgeå æ¯”: {surge_ratio:.2%}")
        
        return df

    # ============================================================
    # ã€æ ¸å¿ƒä¿®å¤ã€‘å› å­èšåˆéƒ¨åˆ† - surge_ret
    # ============================================================
    
    def _aggregate_surge_ret(self, surge_df: pl.DataFrame) -> pl.DataFrame:
        """
        èšåˆsurge_retå› å­
        
        ã€ä¿®å¤æµç¨‹ã€‘
        1. å…ˆç­›é€‰is_surge=Trueçš„barï¼ˆä½¿ç”¨åŸå§‹1m/5m/10m bar_timeï¼‰
        2. ç­›é€‰å®Œä¹‹åï¼Œå†æ˜ å°„åˆ°M10æ—¶é—´ç‚¹è¿›è¡Œèšåˆ
        3. EODæ¨¡å¼ï¼šèšåˆåˆ°æ¯å¤©ä¸€ä¸ªå€¼ï¼Œbar_timeè®¾ä¸º15:00:00.000
        """
        print(f"ğŸ“Š èšåˆsurge_retå› å­: intraday_stat={self.intraday_stat}")
        
        # Step 1: ç­›é€‰surgeæ—¶åˆ»ï¼ˆæ­¤æ—¶è¿˜æ˜¯åŸå§‹çš„1m/5m/10m barï¼‰
        surge_moments = surge_df.filter(pl.col("is_surge") == True)
        
        if len(surge_moments) == 0:
            raise ValueError("æ²¡æœ‰æ£€æµ‹åˆ°surgeæ—¶åˆ»ï¼Œæ— æ³•è®¡ç®—å› å­")
        
        print(f"  - Surgeæ—¶åˆ»æ•°: {len(surge_moments)}")
        
        # Step 2: æ ¹æ®è¾“å‡ºé¢‘ç‡é€‰æ‹©åˆ†ç»„æ–¹å¼
        if self.output_freq == "EOD":
            # EOD: æŒ‰(symbol, date)èšåˆï¼Œä¸éœ€è¦m10æ˜ å°„
            group_cols = ["symbol", "date"]
            agg_expr = pl.col("bar_ret").__getattribute__(self.intraday_stat)().alias("factor_value")
            
            factor_df = (
                surge_moments
                .group_by(group_cols)
                .agg(agg_expr)
            )
        else:
            # M10: ç­›é€‰å®Œsurge baråï¼Œå†æ·»åŠ m10_bar_timeè¿›è¡Œèšåˆ
            # ã€å…³é”®ã€‘è¿™é‡Œæ‰è¿›è¡Œ1m/5måˆ°M10çš„æ˜ å°„
            surge_moments = self._add_m10_bar_time(surge_moments)
            
            print(f"  - æ˜ å°„åˆ°M10æ—¶é—´ç‚¹åè¿›è¡Œèšåˆ")
            
            group_cols = ["symbol", "date", "m10_bar_time"]
            agg_expr = pl.col("bar_ret").__getattribute__(self.intraday_stat)().alias("factor_value")
            
            factor_df = (
                surge_moments
                .group_by(group_cols)
                .agg(agg_expr)
            )
            
            # é‡å‘½åä¸ºbar_timeï¼ˆä¿æŒè¾“å‡ºæ ¼å¼ä¸€è‡´ï¼‰
            factor_df = factor_df.rename({"m10_bar_time": "bar_time"})
        
        print(f"  - èšåˆåè®°å½•æ•°: {len(factor_df)}")
        
        # Step 3: EODæ¨¡å¼æ·»åŠ æ ‡å‡†çš„bar_time (15:00:00.000)
        if self.output_freq == "EOD":
            factor_df = self._add_eod_bar_time(factor_df)
        
        return factor_df
    
    def _add_eod_bar_time(self, factor_df: pl.DataFrame) -> pl.DataFrame:
        """
        ä¸ºEODå› å­æ·»åŠ æ ‡å‡†çš„bar_timeåˆ— (15:00:00.000)
        
        Legionä¿å­˜EODå› å­æ—¶éœ€è¦è¿™ä¸ªæ—¶é—´æˆ³
        """
        # ä»dateåˆ—æ„å»ºå®Œæ•´çš„datetime
        # dateåˆ—å¯èƒ½æ˜¯int (20220104) æˆ– str ("20220104")
        
        dates = factor_df["date"].to_list()
        
        # ç»Ÿä¸€è½¬æ¢ä¸ºdatetimeï¼Œæ—¶é—´éƒ¨åˆ†ä¸º15:00:00
        bar_times = []
        for d in dates:
            if isinstance(d, int):
                d_str = str(d)
            else:
                d_str = d
            dt = datetime.strptime(d_str, "%Y%m%d").replace(hour=15, minute=0, second=0)
            bar_times.append(dt)
        
        return factor_df.with_columns(
            pl.Series("bar_time", bar_times).cast(pl.Datetime)
        )

    # ============================================================
    # å› å­èšåˆéƒ¨åˆ† - surge_vol (ä¿æŒåŸæœ‰é€»è¾‘ï¼Œæ·»åŠ EOD bar_time)
    # ============================================================
    
    def _aggregate_surge_vol(self, surge_df: pl.DataFrame) -> pl.DataFrame:
        """èšåˆsurge_volå› å­"""
        print(f"ğŸ“Š èšåˆsurge_volå› å­: window={self.surge_window}, intraday_stat={self.intraday_stat}")
        
        surge_df = surge_df.with_columns(
            pl.col("is_surge").alias("is_surge_start")
        )
        
        surge_df = self._mark_surge_periods(surge_df)
        
        if self.price_type is not None:
            data_col = self.price_type
            print(f"  - ä½¿ç”¨ä»·æ ¼æ•°æ®: {self.price_type}")
        else:
            data_col = "bar_ret"
            print(f"  - ä½¿ç”¨æ”¶ç›Šç‡æ•°æ®: bar_ret")
        
        period_vol_df = self._calculate_period_volatility(surge_df, data_col)
        
        print(f"  - Surge periodæ•°: {len(period_vol_df)}")
        
        agg_expr = pl.col("period_vol").__getattribute__(self.intraday_stat)().alias("factor_value")
        
        factor_df = (
            period_vol_df
            .group_by(["symbol", "date"])
            .agg(agg_expr)
        )
        
        print(f"  - èšåˆåè®°å½•æ•°: {len(factor_df)}")
        
        # æ·»åŠ æ ‡å‡†çš„bar_time (15:00:00.000)
        factor_df = self._add_eod_bar_time(factor_df)
        
        return factor_df
    
    def _mark_surge_periods(self, surge_df: pl.DataFrame) -> pl.DataFrame:
        """æ ‡è®°surge period"""
        df = surge_df.sort(["symbol", "date", "bar_time"])
        
        df = df.with_columns(
            pl.when(pl.col("is_surge_start"))
            .then(pl.lit(1))
            .otherwise(pl.lit(0))
            .alias("surge_start_flag")
        )
        
        df = df.with_columns(
            pl.col("surge_start_flag")
            .cum_sum()
            .over(["symbol", "date"])
            .alias("period_id")
        )
        
        df = df.with_columns(
            pl.col("bar_time").rank("ordinal").over(["symbol", "date"]).alias("bar_rank")
        )
        
        df = df.with_columns(
            pl.when(pl.col("is_surge_start"))
            .then(pl.lit(True))
            .otherwise(pl.lit(False))
            .alias("in_surge_period")
        )
        
        return df
    
    def _calculate_period_volatility(
        self, 
        surge_df: pl.DataFrame, 
        data_col: str
    ) -> pl.DataFrame:
        """è®¡ç®—æ¯ä¸ªsurge periodçš„æ³¢åŠ¨ç‡"""
        df = surge_df.sort(["symbol", "date", "bar_time"])
        
        df = df.with_columns(
            pl.col(data_col)
            .rolling_std(window_size=self.surge_window, min_periods=self.surge_window)
            .over(["symbol", "date"])
            .alias("period_vol")
        )
        
        period_vol_df = df.filter(
            pl.col("is_surge_start") & pl.col("period_vol").is_not_null()
        )
        
        return period_vol_df.select(["symbol", "date", "bar_time", "period_vol"])

    # ============================================================
    # ä¸»è®¡ç®—æµç¨‹
    # ============================================================
    
    def calculate(self, bizdays_str: str) -> pl.DataFrame:
        """è®¡ç®—surgeå› å­çš„ä¸»æµç¨‹"""
        print(f"\n{'='*60}")    
        print(f"å¼€å§‹è®¡ç®—Surgeå› å­")
        print(f"{'='*60}")
        
        print(f"\n[1/4] åŠ è½½æ•°æ®...")
        bar_df = self.load_and_build_bars(bizdays_str=bizdays_str, add_intraday_ret=True)
        
        print(f"\n[2/4] è¯†åˆ«Surge...")
        surge_df = self._identify_surge(bar_df)
        
        print(f"\n[3/4] èšåˆå› å­...")
        factor_df = self._aggregate_factor(surge_df)
        
        print(f"\n[4/4] ç”Ÿæˆå› å­åç§°...")
        factor_name = self._generate_factor_name()
        factor_df = factor_df.with_columns(
            pl.lit(factor_name).alias("factor_name")
        )
        
        # æ•´ç†è¾“å‡ºåˆ—é¡ºåº
        factor_df = self._format_output(factor_df)
        
        print(f"\n{'='*60}")
        print(f"âœ“ å› å­è®¡ç®—å®Œæˆ: {factor_name}")
        print(f"  - è®°å½•æ•°: {len(factor_df)}")
        print(f"  - è‚¡ç¥¨æ•°: {factor_df['symbol'].n_unique()}")
        print(f"  - æ—¥æœŸæ•°: {factor_df['date'].n_unique()}")
        if "bar_time" in factor_df.columns:
            print(f"  - æ—¶åˆ»æ•°: {factor_df['bar_time'].n_unique()}")
        print(f"{'='*60}\n")
        
        return factor_df
    
    def _format_output(self, factor_df: pl.DataFrame) -> pl.DataFrame:
        """
        æ•´ç†è¾“å‡ºæ ¼å¼
        
        ç¡®ä¿è¾“å‡ºåŒ…å«ï¼šsymbol, date, bar_time, factor_value, factor_name
        """
        # ç¡®å®šè¾“å‡ºåˆ—
        output_cols = ["symbol", "date", "bar_time", "factor_value", "factor_name"]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        existing_cols = [col for col in output_cols if col in factor_df.columns]
        
        return factor_df.select(existing_cols)
    
    def _identify_surge(self, bar_df: pl.DataFrame) -> pl.DataFrame:
        """è¯†åˆ«surgeï¼ˆæ ¹æ®output_freqé€‰æ‹©æ–¹æ³•ï¼‰"""
        if self.output_freq == "EOD":
            return self._identify_surge_eod(bar_df)
        elif self.m10_method == "same_time":
            return self._identify_surge_m10_same_time(bar_df)
        else:
            return self._identify_surge_m10_rolling(bar_df)
    
    def _aggregate_factor(self, surge_df: pl.DataFrame) -> pl.DataFrame:
        """èšåˆå› å­ï¼ˆæ ¹æ®factor_typeé€‰æ‹©æ–¹æ³•ï¼‰"""
        if self.factor_type == "surge_ret":
            return self._aggregate_surge_ret(surge_df)
        else:
            return self._aggregate_surge_vol(surge_df)
    
    def _generate_factor_name(self) -> str:
        """ç”Ÿæˆå› å­åç§°"""
        factor_type_str = "ret" if self.factor_type == "surge_ret" else "vol"
        bar_freq_str = self.bar_freq.lower()
        output_freq_str = self.output_freq.lower()
        
        parts = [f"surge_{factor_type_str}", bar_freq_str, output_freq_str]
        
        if self.output_freq == "EOD":
            trading_time_str = self.trading_time.replace("_", "")
            parts.append(trading_time_str)
            
            if self.factor_type == "surge_vol":
                parts.append(f"w{self.surge_window}")
                if self.price_type:
                    parts.append(self.price_type)
        else:
            if self.m10_method == "same_time":
                parts.append("sametime")
                parts.append(f"d{self.lookback_days}")
            else:
                parts.append("rolling")
                parts.append(f"k{self.lookback_bars}")
        
        parts.append(f"t{self.threshold}")
        parts.append(self.intraday_stat)

        factor_name = "_".join(parts)
        
        return factor_name

    def get_lookback_days(self) -> int:
        """è·å–è¯¥å› å­éœ€è¦çš„å›çœ‹å¤©æ•°"""
        if self.output_freq == "EOD":
            return 0
        elif self.m10_method == "same_time":
            return self.lookback_days
        else:
            bars_per_day = get_bar_count_per_day(self.bar_freq)
            return (self.lookback_bars // bars_per_day) + 1

    def calculate_single_day(
        self, 
        settlement_date: str,
        bar_data: pl.DataFrame = None
    ) -> pl.DataFrame:
        """è®¡ç®—å•ä¸ªç»“ç®—æ—¥çš„å› å­"""
        if bar_data is None:
            lookback = self.get_lookback_days()
            start_date = bizday(settlement_date, -lookback) if lookback > 0 else settlement_date
            date_list = bizdays(f"{start_date}-{settlement_date}")
            bar_data = self.load_and_build_bars(date_list=date_list, add_intraday_ret=True)
        
        self.bar_data = bar_data
        
        surge_df = self._identify_surge(bar_data)
        factor_df = self._aggregate_factor(surge_df)
        
        date_col_dtype = factor_df["date"].dtype
        if date_col_dtype == pl.Utf8:
            filter_value = settlement_date
        else:
            filter_value = int(settlement_date)
        
        factor_df = factor_df.filter(pl.col("date") == filter_value)
        
        factor_name = self._generate_factor_name()
        factor_df = factor_df.with_columns(
            pl.lit(factor_name).alias("factor_name")
        )
        
        # æ•´ç†è¾“å‡ºæ ¼å¼
        factor_df = self._format_output(factor_df)
        
        return factor_df
